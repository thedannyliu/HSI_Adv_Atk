# Configuration File for HyperForensics++ Training (DFCN Style)

GENERAL:
  SEED: 42  # Random seed for reproducibility

CUDA:
  USE_CUDA: True
  CUDA_NUM: [4] # Modify to list the GPU IDs you want to use, e.g., [0] or [0, 1]

DATASET:
  # IMPORTANT: Set this root to your actual dataset location
  ROOT: "/ssd8/HyperForensics_Data/HyperForensics_Dataset/ADMM_ADAM/"
  # IMPORTANT: These point to the list files you MUST create in the project root
  # Relative path from scripts/train.py or scripts/performance_eval.py
  Train_data: "../train_all.txt" # Combined list for config0-4 train data
  Val_data: "../val_all.txt"   # Combined list for config0-4 val data
  NUM_CLASSES: 2

MODEL:
  NAME: "HRNetV2"
  C: 12           # Base channels for HRNet stages (DFCN default)
  IN_CHANNELS: 172 # Input HSI channels
  USE_3D: True    # Use the 3D Conv frontend (SSF-like) - Set True to match DFCN
  USE_ATTENTION: True # 啟用Attention以便使用SKConv (與DFCN_Py匹配)
  PRETRAINED: False # Set path if loading pretrained weights

TRAIN:
  EPOCH_START: 1
  EPOCH_END: 1000 # 增加訓練輪數到1000輪，與DFCN_Py更接近
  BATCH_SIZE: 8  # 增加批次大小，如果GPU記憶體允許，可以設置為16
  LEARNING_RATE: 0.001 # 提高學習率到DFCN_Py使用的0.001
  WEIGHT_DECAY: 0.00005 # 保持不變，與DFCN一致
  NUM_WORKERS: 8  # DataLoader workers (Adjust based on CPU cores)
  PIN_MEMORY: True

  # Logging and Saving
  LOG_PATH: "./logs/training_log_dfcn" # Relative path for TensorBoard logs
  SAVE_WEIGHT_PATH: "./checkpoints_dfcn" # Relative path for model checkpoints
  LOG_LOSS: 10      # Log loss to TensorBoard every N batches
  LOG_IMAGE: 50     # Log images to TensorBoard every N batches
  SAVE_WEIGHT_STEP: 4 # Validate and save model every N epochs (DFCN default)
  CHECKPOINT: ''    # Path to checkpoint to resume training, e.g., './checkpoints_dfcn/last.pth'
  VAL_FREQ: 4       # Frequency of running validation (matches SAVE_WEIGHT_STEP)

  # Loss Function
  LOSS:
    NAME: "DiceBCELoss" # 改為使用DiceBCELoss，DFCN_Py中使用了此損失函數
    WEIGHTS: [0.01, 0.99] # 保持類別權重不變
  BAND_REG: True # 啟用頻譜正則化，與DFCN_Py一致

  # Optimizer (Only AdamW settings relevant here from DFCN)
  OPTIMIZER:
    NAME: "AdamW"
    # Betas are typically handled directly in optimizer creation

  # Scheduler (MultiStepLR settings from DFCN)
  SCHEDULER:
    NAME: "MultiStepLR"
    MILESTONES: [400, 700, 900] # 調整里程碑點，使其更適合1000輪訓練
    GAMMA: 0.1 # LR decay factor

TEST: # Settings used for validation during training
  BATCH_SIZE: 8 # 增加驗證批次大小
  NUM_WORKERS: 4
  # CHECKPOINT: # Not needed here, trainer uses current model
  RESULTS_NUM: 5 # Number of validation images to save per validation run
  RESULTS_PATH: './logs/validation_results_dfcn' # Path to save validation image results 